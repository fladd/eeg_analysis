{
 "metadata": {
  "name": "",
  "signature": "sha256:f7bec0ed4046b6bbff257df2f70f845ac0d8b73d623b93a8ad52510f5780abc1"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Example EEG analysis"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is an example analysis of EEG data in Python, using the [MNE package](http://martinos.org/mne/stable/mne-python.html).\n",
      "\n",
      "The data comes from an auditory oddball paradigm which consisted of 500 tones of which 10% where higher in pitch.\n",
      "\n",
      "The data was recorded with a BrainVision 64-channel EEG system, using BrainVision Recorder."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Preparations"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Make sure you have [IPython](http://www.ipython.org), [MNE](http://martinos.org/mne/stable/mne-python.html), [Numpy](http://www.numpy.org) and [Matplotlib](http://www.matplotlib.org) installed.\n",
      "\n",
      "Download the [example data set](http://stuff.fladd.de/copy/dl/Example_EEG_data.zip) and the [BrainCap MR 3-0 64Ch layout file](http://stuff.fladd.de/copy/dl/BC-MR-64_58cm.lout)."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Settings"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We first import the necessary python packages and define some global variables, to have all the parameters of the experiment in one central place."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%pylab inline\n",
      "import os\n",
      "\n",
      "import mne\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "N_JOBS = 8  # The number of jobs to use for computations\n",
      "DATA_PATH = \"Documents/eeg/Sascha_Oddball/\"  # The path to the data\n",
      "FILENAME = \"Sascha_Oddball\"  # The filename without extension\n",
      "LAYOUT_FILE = \"/Users/floriankrause/BC-MR-64_58cm.lout\"  # The full path to the layout file\n",
      "MAX_CHANNEL_STD = 2.5  # The threshold to exclude bad channels (in standard deviations)\n",
      "HIGHPASS = (0.5, 0.25)  # (Frequency in Hz, Transition Bandwidth in Hz)\n",
      "LOWPASS = (40, 0.25)  # Frequency in Hz, Transition Bandwidth in Hz)\n",
      "CONDITIONS = {\"Regular\": 3,\n",
      "              \"Odd\": 4}\n",
      "EPOCH = (-0.1, 0.8)  # In seconds\n",
      "BASELINE = (-0.1, 0)  # In seconds\n",
      "N_COMPONENTS = 0.90  # If integer, then number of components, if float, then percentage of explained signal\n",
      "CH_OF_INTEREST = \"Cz\"  # The channel to look at\n",
      "TFR_RANGE = (7, 30, 3)  # The range for time-frequency analyses\n",
      "ALPHA_LEVEL = 0.05\n",
      "N_PERMUTATIONS = 1000"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Import BrainVision raw data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "MNE can load data in the BrainVision recorder format. We, however, need to define that channel 32 is an ECG dropdown electrode, so we can later on process this channel independently from the EEG channels."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "raw = mne.io.brainvision.read_raw_brainvision(os.path.join(DATA_PATH, FILENAME + \".vhdr\"), preload=True)\n",
      "raw.info['chs'][raw.info[\"ch_names\"].index(\"ECG\")]['kind'] = mne.io.constants.FIFF.FIFFV_ECG_CH\n",
      "print raw.info"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Plot raw data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can make an interactive plot of the raw data to visually inspect it (e.g. to look manually for bad electrodes)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "raw.plot()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Preprocessing"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Before running analyses on the data, we first need to remove bad channels, filter the data, create epochs of our conditions, and run an Independent Component Analysis (ICA) to remove artifacts. "
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Mark bad EEG channels"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It can happen that an electrode is broken or got loose during the experiment. Those electrodes will give a very bad signal, so let's remove it. We can remove them automatically by a certain threshold (in standard deviations from the rest), or manually after our visual inspection."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Automatic\n",
      "eeg_chs = mne.pick_types(raw.info, eeg=True)\n",
      "raw_eeg = raw._data[eeg_chs]\n",
      "var = [np.std(x) for x in raw_eeg]\n",
      "crit = np.mean(var) + np.std(var) * MAX_CHANNEL_STD\n",
      "raw.info['bads'] += [raw.info[\"ch_names\"][eeg_chs[var.index(x)]] for x in var if x > crit]\n",
      "\n",
      "# Manual (if needed)\n",
      "#raw.info['bads'] += ['Cz']\n",
      "\n",
      "print raw.info['bads']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Filter EEG channels"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To exclude noise, filter the data to the frequency range relevant for ERPs and time-frequency analyses."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "eeg_chs = mne.pick_types(raw.info, eeg=True, ecg=False, exclude='bads')\n",
      "raw.filter(HIGHPASS[0], LOWPASS[0], picks=eeg_chs, n_jobs=N_JOBS,\n",
      "           l_trans_bandwidth=HIGHPASS[1], h_trans_bandwidth=LOWPASS[1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Filter ECG channel"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can also 'clean' our ECG signal by removing information that is not affected by the cardio rhythm."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ecg_ch = mne.pick_types(raw.info, eeg=False, ecg=True, exclude='bads')\n",
      "raw.filter(0.5, 150, picks=ecg_ch, n_jobs=N_JOBS,\n",
      "           l_trans_bandwidth=0.25, h_trans_bandwidth=0.25)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Run ICA decomposition"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Every EEG data will, in addition to the signal we are interested in, contain artifacts which are related to the cardiac rhythm, (eye-)movements or general noise. ICA tries to decompose a signal into the several single components it is made of, giving us a chance to identify and remove those components that are related to noise, while leaving in the ones that are related to the signal we are interested in. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "ica = mne.preprocessing.ICA(n_components=N_COMPONENTS, method='fastica')\n",
      "ica.fit(raw)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Plot components"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To visually inspect the identified components, we will look at their time courses and topographies."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "layout = mne.layouts.read_layout(LAYOUT_FILE)\n",
      "ica.plot_components(ch_type='eeg', layout=layout, show=False)\n",
      "ica.plot_sources(raw)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Mark components for removal"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can let an algorithm try to detect components that are correlated to the ECG channel, or suspicious in terms of skewness, kurtosis and variance, and/or we can remove components manually, based on the visual inspection."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Automatic\n",
      "ica.exclude = []\n",
      "ica.detect_artifacts(raw, ecg_ch=\"ECG\", eog_ch=None, ecg_criterion=0.1, eog_criterion=0.1,\n",
      "                     skew_criterion=-1, kurt_criterion=-1, var_criterion=0)\n",
      "\n",
      "print ica.exclude\n",
      "# Manual (if needed)\n",
      "#ica.exclude = [1, 6]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Check effect of componant removal"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To get an idea of what the effect of removing the marked componants will be, we plot the difference in the average of our raw data between before and after the ICA componant removal."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ica.plot_overlay(raw)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Remove components from raw data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Once we are sure about our component selection, we can now remove them from our raw data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "raw_clean = ica.apply(raw, copy=True)\n",
      "raw_old = raw\n",
      "raw = raw_clean"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Epoch raw data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For further analysis, we create epochs for each condition. The epoch will be automatically corrected for the baseline."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "events = mne.find_events(raw)\n",
      "print events\n",
      "\n",
      "chs = mne.pick_types(raw.info, eeg=True, exclude='bads')\n",
      "epochs = mne.Epochs(raw, events, CONDITIONS, EPOCH[0], EPOCH[1],\n",
      "                    baseline=BASELINE, picks=chs, preload=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Analysis"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To get an idea of our experimental effects, we will be looking at evoked repsonses and at the time-frequency representation."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Compute and plot evoked responses"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Averaging over our epochs of each condition, will give us the evoked responses, wich we can plot over all electrodes."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "evokeds = [epochs[x].average() for x in CONDITIONS.keys()]\n",
      "print evokeds\n",
      "\n",
      "layout = mne.layouts.read_layout(LAYOUT_FILE)\n",
      "mne.viz.plot_topo(evokeds, layout=layout)\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Test for differences in evoked responses between two conditions"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can now perform a non-parametric permutation cluster test to compare if the evoked responses between conditions are significant for a specific channel, and plot the results."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "conditions = [epochs[x].get_data() for x in CONDITIONS.keys()]  # Get data for each condition\n",
      "conditions = [x[:, epochs.ch_names.index(CH_OF_INTEREST), :] for x in conditions]  # Limit data to a specific channel\n",
      "\n",
      "# Perform permutation test\n",
      "T_obs, clusters, cluster_p_values, H0 = \\\n",
      "                mne.stats.permutation_cluster_test([conditions[1], conditions[0]],\n",
      "                                                   n_permutations=N_PERMUTATIONS,\n",
      "                                                   n_jobs=N_JOBS)\n",
      "    \n",
      "# Plot results\n",
      "times = epochs[CONDITIONS.keys()[0]].times * 1000\n",
      "plt.close('all')\n",
      "plt.subplot(211)\n",
      "plt.title('Channel : ' + CH_OF_INTEREST)\n",
      "plt.plot(times, (conditions[1].mean(axis=0) - conditions[0].mean(axis=0)) * 1000000,\n",
      "         label=\"ERP Contrast (Event 2 - Event 1)\")\n",
      "plt.ylabel(\"EEG (uV)\")\n",
      "plt.legend()\n",
      "plt.subplot(212)\n",
      "for i_c, c in enumerate(clusters):\n",
      "    c = c[0]\n",
      "    if cluster_p_values[i_c] <= ALPHA_LEVEL:\n",
      "        h = plt.axvspan(times[c.start], times[c.stop - 1],\n",
      "                        color='r', alpha=0.3)\n",
      "    else:\n",
      "        plt.axvspan(times[c.start], times[c.stop - 1], color=(0.3, 0.3, 0.3),\n",
      "                    alpha=0.3)\n",
      "hf = plt.plot(times, T_obs, 'g')\n",
      "plt.legend((h, ), ('Cluster p-value < {0}'.format(ALPHA_LEVEL), ))\n",
      "plt.xlabel(\"Time (ms)\")\n",
      "plt.ylabel(\"t-values\")\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Compute and plot time-frequency differences"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To compare the power spectra between conditions, we need to calculate the time-frequency representation. We then use cluster testing again to plot the significant clusters for a specific channel."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "conditions = [epochs[x].get_data() for x in CONDITIONS.keys()]  # Get data for each condition\n",
      "conditions = [x * 1000000 for x in conditions]  # Convert to microvolt\n",
      "conditions = [x[:, epochs.ch_names.index(CH_OF_INTEREST):epochs.ch_names.index(CH_OF_INTEREST)+1, :] for x in conditions]  # Limit data to a specific channel\n",
      "\n",
      "times = 1000 * epochs[0].times\n",
      "decim = 2\n",
      "\n",
      "baseline_mask = times < 0\n",
      "\n",
      "epochs_powers = []\n",
      "for x in conditions:\n",
      "    epochs_power = mne.time_frequency.single_trial_power(x, Fs=raw.info['sfreq'],\n",
      "                                                          frequencies=TFR_RANGE,\n",
      "                                                          n_cycles=1.5, use_fft=False,\n",
      "                                                          n_jobs=N_JOBS)\n",
      "    epochs_power = epochs_power[:, 0, :, :]  # Only take one channel\n",
      "    \n",
      "    # Compute ratio with baseline power\n",
      "    epochs_baseline = np.mean(epochs_power[:, :, baseline_mask], axis=2)\n",
      "    epochs_power /= epochs_baseline[..., np.newaxis]\n",
      "    epochs_powers.append(epochs_power)\n",
      "\n",
      "# Perform the permutation test\n",
      "T_obs, clusters, cluster_p_values, H0 = \\\n",
      "                   mne.stats.permutation_cluster_test([epochs_powers[1], epochs_powers[0]],\n",
      "                                                      tail=0, n_permutations=N_PERMUTATIONS,\n",
      "                                                      n_jobs=N_JOBS)\n",
      "\n",
      "# Create time-frequency plots\n",
      "import matplotlib.pyplot as plt\n",
      "plt.clf()\n",
      "plt.subplots_adjust(0.12, 0.08, 0.96, 0.94, 0.2, 0.43)\n",
      "plt.subplot(2, 1, 1)\n",
      "evoked_contrast = np.mean(conditions[1], 0) - np.mean(conditions[0], 0)\n",
      "plt.plot(times, evoked_contrast.T)\n",
      "plt.title('Contrast of evoked response (%s)' % CH_OF_INTEREST)\n",
      "plt.xlabel('Time (ms)')\n",
      "plt.ylabel('EEG (uV)')\n",
      "plt.xlim(times[0], times[-1])\n",
      "\n",
      "plt.subplot(2, 1, 2)\n",
      "\n",
      "# Create new stats image with only significant clusters plotted in colour\n",
      "T_obs_plot = np.nan * np.ones_like(T_obs)\n",
      "for c, p_val in zip(clusters, cluster_p_values):\n",
      "    if p_val <= ALPHA_LEVEL:\n",
      "        T_obs_plot[c] = T_obs[c]\n",
      "\n",
      "plt.imshow(T_obs, cmap=plt.cm.gray,\n",
      "           extent=[times[0], times[-1], TFR_RANGE[0], TFR_RANGE[1]],\n",
      "           aspect='auto', origin='lower')\n",
      "plt.imshow(T_obs_plot, cmap=plt.cm.jet,\n",
      "           extent=[times[0], times[-1], TFR_RANGE[0], TFR_RANGE[1]],\n",
      "           aspect='auto', origin='lower')\n",
      "\n",
      "plt.xlabel('Time (ms)')\n",
      "plt.ylabel('Frequency (Hz)')\n",
      "plt.title('Induced power (%s)' % CH_OF_INTEREST)\n",
      "plt.show()\n",
      "\n",
      "\n",
      "\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}